# task type, support train and predict
task = train

# boosting type, support gbdt for now, alias: boosting, boost
boosting_type = gbdt


objective = binary


metric = binary_error,auc

# weight_column
weight = 0


#ignore
#ignore_column = name:customerid,callhisid,calltime   
#max_onlinetime,connect_times,onlinetime_gap


# frequence for metric output
metric_freq = 1

# true if need output metric for training data, alias: tranining_metric, train_metric
is_training_metric = true

# number of bins for feature bucket, 255 is a recommend setting, it can save memories, and also has good accuracy.
max_bin = 255


data = jieqing_train

valid_data = jieqing_test_1,jieqing_test_10
# number of trees(iterations), alias: num_tree, num_iteration, num_iterations, num_round, num_rounds
num_trees = 100

#num_iteration = 500

# shrinkage rate , alias: shrinkage_rate
learning_rate = 0.05

# number of leaves for one tree, alias: num_leaf
num_leaves = 3

early_stopping_round = 30

# type of tree learner, support following types:
# serial , single machine version
# feature , use feature parallel to train
# data , use data parallel to train
# voting , use voting based parallel to train
# alias: tree
tree_learner = voting

# number of threads for multi-threading. One thread will use one CPU, defalut is setted to #cpu.
# num_threads = 8

# feature sub-sample, will random select 80% feature to train on each iteration
# alias: sub_feature
feature_fraction = 0.9

max_depth = 100
# minimal number data for one leaf, use this to deal with over-fit
# alias : min_data_per_leaf, min_data
min_data_in_leaf = 130

# minimal sum hessians for one leaf, use this to deal with over-fit
min_sum_hessian_in_leaf = 50.0



# Support bagging (data sub-sample), will perform bagging every 5 iterations
bagging_freq = 1

# Bagging farction, will random select 80% data on bagging
# alias: sub_row
bagging_fraction = 0.85


# save memory and faster speed for sparse feature, alias: is_sparse
is_enable_sparse = true

# when data is bigger than memory size, set this to true. otherwise set false will have faster speed
# alias: two_round_loading, two_round
use_two_round_loading = false

# true if need to save data to binary file and application will auto load data from binary file next time
# alias: is_save_binary, save_binary
is_save_binary_file = false

#header
header = true

# output model file
output_model = dianxiao1.txt,dianxiao10.txt




#category feature
#categorical_feature = name:is_old,mobile_type

# support continuous train from trained gbdt model
# input_model= trained_model.txt

# output prediction file for predict task
# output_result= prediction.txt


